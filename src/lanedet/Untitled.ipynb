{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DATA_PATH = \"../../DATA\"\n",
    "DATA_SET = \"test_clip_2017_03_1\"\n",
    "LIST_FILE = \"labelled_samples2_done2.json\"\n",
    "TRAIN_SPLIT_RATIO = 0.7\n",
    "# Model Hyper-parameters\n",
    "INPUT_CHANNELS = 3\n",
    "KSIZE1 = 3\n",
    "KNUM1 = 32\n",
    "KSIZE2 = 3\n",
    "KNUM2 = 64\n",
    "HIDDEN_UNITS_NUM1 = 256\n",
    "LOCATION_NUM = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DETECTION_AREA_WIDTH = 500\n",
    "DETECTION_AREA_HEIGHT = 20\n",
    "\n",
    "with open(os.path.join(DATA_PATH, DATA_SET, LIST_FILE), 'r') as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "roi = d['roi']\n",
    "samples = d['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def _get_labelled_images(samples, fullname_fn):\n",
    "    \"\"\"\n",
    "    :param samples a list, samples[i] is\n",
    "      [filename, [x-coordinates of control points], [y-...]]\n",
    "    :param fullname_fn: converts file name to full.\n",
    "    \"\"\"\n",
    "    train_images = []\n",
    "    label_images = []\n",
    "    mean_bgr_ = np.zeros(3)\n",
    "    for fname, xs, ys in samples:\n",
    "        im = cv2.imread(fullname_fn(fname))\n",
    "        label_im = np.zeros_like(im[:,:,0])\n",
    "        for x0, x1, y0, y1  in zip(xs[:-1], xs[1:], ys[:-1], ys[1:]):\n",
    "            cv2.line(label_im, (int(x0), int(y0)), (int(x1), int(y1)), 255, 2)\n",
    "            \n",
    "        x0_, x1_ = roi['left'], roi['left'] + roi['width']\n",
    "        y0_, y1_ = roi['top'], roi['top'] + roi['height']\n",
    "        \n",
    "        train_images.append(im[y0_:y1_, x0_:x1_, :])\n",
    "        label_images.append(label_im[y0_:y1_, x0_:x1_])\n",
    "        \n",
    "        mean_bgr_ += train_images[-1].mean(axis=0).mean(axis=0)\n",
    "\n",
    "        # im2 = cv2.addWeighted(im, 0.5, cv2.cvtColor(label_im, cv2.COLOR_GRAY2BGR), 0.5, 0)\n",
    "        # cv2.imshow(\"a\", im2)\n",
    "        # cv2.waitKey()\n",
    "    # cv2.destroyAllWindows()\n",
    "    return train_images, label_images, mean_bgr_ / len(train_images)\n",
    "        \n",
    "fullname_fn = lambda x: os.path.join(DATA_PATH, x)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_code_h(label_im, num_classes):\n",
    "    \"\"\"\n",
    "    Encode the horizontal position of the labels -- the left most pixel\n",
    "    \"\"\"\n",
    "    onehot_code = np.zeros(num_classes+1, dtype=np.uint8)\n",
    "    w = label_im.shape[1]\n",
    "    _, xs = np.nonzero(label_im)\n",
    "    if xs.size > 0:\n",
    "        xmin = np.min(xs)\n",
    "        pos_w = float(w) / num_classes\n",
    "        cls_id = int(float(xmin) / pos_w)\n",
    "        onehot_code[cls_id] = 1\n",
    "    else:\n",
    "        xmin = -1\n",
    "        onehot_code[-1] = 1\n",
    "        cls_id = num_classes\n",
    "        \n",
    "    return onehot_code, cls_id, xmin\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debug_display = False\n",
    "sample_num = 100\n",
    "\n",
    "x_offset_max = train_images[0].shape[1] - DETECTION_AREA_WIDTH\n",
    "y_offset_max = train_images[0].shape[0] - DETECTION_AREA_HEIGHT\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# for each\n",
    "# input_x, gnd_y\n",
    "input_x = []\n",
    "gnd_y = []\n",
    "for i in range(sample_num):\n",
    "    image_id = rng.randint(len(train_images))\n",
    "\n",
    "    x0_, y0_ = rng.randint(x_offset_max), rng.randint(y_offset_max)\n",
    "    x1_, y1_ = x0_ + DETECTION_AREA_WIDTH, y0_ + DETECTION_AREA_HEIGHT\n",
    "\n",
    "    train_area = train_images[image_id][y0_:y1_, x0_:x1_, :]\n",
    "    label_area = label_images[image_id][y0_:y1_, x0_:x1_]\n",
    "    cls_code, cls_id, _ = get_label_code_h(label_area, LOCATION_NUM)\n",
    "    input_x.append(np.rollaxis(preprocessor(train_area, mean_bgr),2))\n",
    "    gnd_y.append(cls_id)\n",
    "\n",
    "    if debug_display:\n",
    "        im2 = train_images[image_id].copy()\n",
    "        im2l = cv2.cvtColor(label_area, cv2.COLOR_GRAY2BGR)\n",
    "        if cls_id < LOCATION_NUM:\n",
    "            bx0_ = int(cls_id * float(DETECTION_AREA_WIDTH) / LOCATION_NUM)\n",
    "            bx1_ = int((cls_id+1) * float(DETECTION_AREA_WIDTH) / LOCATION_NUM)\n",
    "            im2l[:, bx0_:bx1_, 1] = 255\n",
    "            print cls_id, cls_code\n",
    "        else:\n",
    "            im2l[..., 2] += 128\n",
    "        \n",
    "        im2[y0_:y1_, x0_:x1_, :] = \\\n",
    "            cv2.addWeighted(im2[y0_:y1_, x0_:x1_, :], 0.5, im2l, 0.5, 0)\n",
    "        cv2.imshow(\"a\", im2)\n",
    "        cv2.waitKey()\n",
    "        \n",
    "if debug_display: \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.permutation(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    a = range(10)\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield a[i:i+2]\n",
    "        i += 2\n",
    "        if i>=9:\n",
    "            i=0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [ (i, iv)\n",
    "     for i, iv in zip(range(10), get_sample()) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts = {'image_width': DETECTION_AREA_WIDTH, 'image_height': DETECTION_AREA_HEIGHT}\n",
    "ldet = LaneCloseDetectNet(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Variable(torch.from_numpy(np.ascontiguousarray(input_x)), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = Variable(torch.LongTensor(gnd_y), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = ldet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(pred, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "optimiser = torch.optim.Adagrad(ldet.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimiser.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i_ in range(10):\n",
    "    pred = ldet(X)\n",
    "    loss = loss_fn(pred, Y)\n",
    "    print i_, loss\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE and LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join('tmp-save-10')\n",
    "torch.save(ldet.state_dict(), fname)                      \n",
    "# with open(checkpoint_status_file, 'w') as f:                    \n",
    "#     json.dump({'episode': episode,                              \n",
    "# 309                                'running_loss': running_loss,                    \n",
    "# 310                                'running_reward': running_reward,                \n",
    "# 311                                'loss_history': loss_history,                    \n",
    "# 312                                'reward_history': reward_history}, f, indent=2)  \n",
    "# 313                 print \"Save model to {}\".format(fname)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldet2 = LaneCloseDetectNet(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldet2.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pred = ldet2(X)\n",
    "loss = loss_fn(pred, Y)\n",
    "print i_, loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batch-0, Episode-0, Batch-0, Loss 4.78446292877\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-1, Loss 4.31895923615\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-2, Loss 3.42922401428\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-3, Loss 3.61986994743\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-4, Loss 3.33856344223\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-5, Loss 3.84738588333\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-6, Loss 4.03854656219\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-7, Loss 4.38210868835\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-8, Loss 3.72667813301\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-9, Loss 3.50473070145\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-10, Loss 3.78440403938\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-11, Loss 3.21428418159\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-12, Loss 3.20977020264\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-13, Loss 4.05854511261\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-14, Loss 3.6845536232\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-15, Loss 3.0101108551\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-16, Loss 3.3341178894\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-17, Loss 4.22801065445\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-18, Loss 4.08236551285\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-19, Loss 3.39288949966\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-20, Loss 3.92334485054\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-21, Loss 3.16484165192\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-22, Loss 3.07229685783\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-23, Loss 3.18073749542\n",
      "Model Saved to ../../RUNS/detector_snapshots/checkpoint-0\n",
      "Total Batch-0, Episode-0, Batch-24, Loss 3.46063351631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/junli/local/projects/precloc/src/lanedet/train_lane_detectpr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/junli/local/projects/precloc/src/lanedet/train_lane_detectpr.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train_lane_detectpr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data()\n",
    "train_set = data.data_source('train', minibatch=20)\n",
    "valid_set = data.data_source('valid', minibatch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,e,b = train_set.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "4.6999998 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-23a10b24de37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmptmp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/junli/toolbox/anaconda2/envs/tf/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is not JSON serializable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 4.6999998 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('tmptmp', 'w') as f:\n",
    "    json.dump({'a': a}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.float32(4.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6999998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tf]",
   "language": "python",
   "name": "Python [tf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
